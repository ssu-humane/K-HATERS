{"alpha": 0.5, "att_lambda": 1.0, "attention": "N/A", "auto_weights": false, "batch_size": 32, "bert_tokens": true, "decay": "False", "device": "cuda", "drop_embed": "N/A", "drop_fc": "N/A", "drop_hidden": "N/A", "dropout_bert": 0.1, "embed_size": "N/A", "embeddings": "N/A", "epochs": 5, "epsilon": 1e-08, "hidden_size": 768, "include_special": "False", "is_model": "True", "learning_rate": 2e-05, "logging": "local", "majority": 2.0, "max_length": 128, "method": "additive", "model_name": "birnn", "normalized": "False", "not_recollect": "True", "num_classes": 4, "num_supervised_heads": 1, "p_value": 0.8, "padding_idx": "N/A", "path_files": "beomi/kcbert-base", "random_seed": 10, "save_only_bert": "False", "seq_model": "N/A", "set_decay": 0.1, "supervised_layer_pos": 11.0, "to_save": true, "train_att": "False", "train_embed": "N/A", "type_attention": "softmax", "variance": 5.0, "vocab_size": "N/A", "weights": [1.0, 1.0, 1.0, 1.0], "what_bert": "weighted", "window": 4.0, "hate_alpha": 1, "target_beta": 1, "auto_weight": true, "path_files_name": "kcbert"}